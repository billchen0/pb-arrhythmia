{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import xml.etree.ElementTree as ET\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_ecg_data(root):\n",
    "    # Define the namespace\n",
    "    namespaces = {\"ns\": \"urn:hl7-org:v3\"}\n",
    "\n",
    "    # Extract the sequence id and other sequence related metadata\n",
    "    seq_id = root.find(\".//ns:id\", namespaces).attrib[\"root\"]\n",
    "    subject_id = root.find(\".//ns:trialSubject/ns:id\", namespaces).attrib[\"extension\"]\n",
    "    acq_time = root.find(\".//ns:effectiveTime/ns:low\", namespaces).attrib[\"value\"]\n",
    "\n",
    "    # Initialize a dictionary to hold the ECG data\n",
    "    ecg_data = {\n",
    "        \"sequence_id\": seq_id,\n",
    "        \"subject_id\": subject_id,\n",
    "        \"acq_time\": acq_time\n",
    "    }\n",
    "\n",
    "    # Extract the ECG signal, unit, and scale\n",
    "    for component in root.findall(\".//ns:sequenceSet/ns:component\", namespaces)[1:13]:\n",
    "        sequence = component.find(\".//ns:sequence\", namespaces)\n",
    "        if sequence is not None:\n",
    "            lead = sequence.find(\".//ns:code\", namespaces).attrib[\"code\"]\n",
    "            scale = float(sequence.find(\".//ns:scale\", namespaces).attrib[\"value\"])\n",
    "            signal = [int(x)*scale for x in sequence.find(\".//ns:digits\", namespaces).text.strip().split()]\n",
    "        \n",
    "            # Add each lead's signal to the data dictionary\n",
    "            ecg_data[f'lead_{lead}'] = signal\n",
    "\n",
    "    return ecg_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path(\"/media/nvme1/pbecg-data/fda\")\n",
    "all_ecg_data = []\n",
    "for file_path in data_path.rglob(\"*xml\"):\n",
    "    tree = ET.parse(file_path)\n",
    "    root = tree.getroot()\n",
    "    ecg_data = extract_ecg_data(root)\n",
    "    all_ecg_data.append(ecg_data)\n",
    "\n",
    "df = pd.DataFrame(all_ecg_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill NaN values in the first set of columns with values from the second set of columns\n",
    "df['lead_MDC_ECG_LEAD_aVR'].fillna(df['lead_MDC_ECG_LEAD_AVR'], inplace=True)\n",
    "df['lead_MDC_ECG_LEAD_aVL'].fillna(df['lead_MDC_ECG_LEAD_AVL'], inplace=True)\n",
    "df['lead_MDC_ECG_LEAD_aVF'].fillna(df['lead_MDC_ECG_LEAD_AVF'], inplace=True)\n",
    "\n",
    "# Drop the second set of columns\n",
    "df.drop(columns=['lead_MDC_ECG_LEAD_AVR', 'lead_MDC_ECG_LEAD_AVL', 'lead_MDC_ECG_LEAD_AVF'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bc299/miniconda3/envs/pb/lib/python3.10/site-packages/pyarrow/pandas_compat.py:373: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if _pandas_api.is_sparse(col):\n"
     ]
    },
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: '/media/nvme1/pbecg-data/signal.parquet'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m/home/bc299/pbecg/prepare_dataset.ipynb Cell 5\u001b[0m line \u001b[0;36m5\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bwil.egr.duke.edu/home/bc299/pbecg/prepare_dataset.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m# Store the dataset as a parquet file\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bwil.egr.duke.edu/home/bc299/pbecg/prepare_dataset.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m save_path \u001b[39m=\u001b[39m Path(\u001b[39m\"\u001b[39m\u001b[39m/media/nvme1/pbecg-data/signal.parquet\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bwil.egr.duke.edu/home/bc299/pbecg/prepare_dataset.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m df\u001b[39m.\u001b[39;49mto_parquet(save_path, index\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n",
      "File \u001b[0;32m~/miniconda3/envs/pb/lib/python3.10/site-packages/pandas/core/frame.py:2973\u001b[0m, in \u001b[0;36mDataFrame.to_parquet\u001b[0;34m(self, path, engine, compression, index, partition_cols, storage_options, **kwargs)\u001b[0m\n\u001b[1;32m   2885\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   2886\u001b[0m \u001b[39mWrite a DataFrame to the binary parquet format.\u001b[39;00m\n\u001b[1;32m   2887\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2969\u001b[0m \u001b[39m>>> content = f.read()\u001b[39;00m\n\u001b[1;32m   2970\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   2971\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mio\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mparquet\u001b[39;00m \u001b[39mimport\u001b[39;00m to_parquet\n\u001b[0;32m-> 2973\u001b[0m \u001b[39mreturn\u001b[39;00m to_parquet(\n\u001b[1;32m   2974\u001b[0m     \u001b[39mself\u001b[39;49m,\n\u001b[1;32m   2975\u001b[0m     path,\n\u001b[1;32m   2976\u001b[0m     engine,\n\u001b[1;32m   2977\u001b[0m     compression\u001b[39m=\u001b[39;49mcompression,\n\u001b[1;32m   2978\u001b[0m     index\u001b[39m=\u001b[39;49mindex,\n\u001b[1;32m   2979\u001b[0m     partition_cols\u001b[39m=\u001b[39;49mpartition_cols,\n\u001b[1;32m   2980\u001b[0m     storage_options\u001b[39m=\u001b[39;49mstorage_options,\n\u001b[1;32m   2981\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m   2982\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/pb/lib/python3.10/site-packages/pandas/io/parquet.py:483\u001b[0m, in \u001b[0;36mto_parquet\u001b[0;34m(df, path, engine, compression, index, storage_options, partition_cols, filesystem, **kwargs)\u001b[0m\n\u001b[1;32m    479\u001b[0m impl \u001b[39m=\u001b[39m get_engine(engine)\n\u001b[1;32m    481\u001b[0m path_or_buf: FilePath \u001b[39m|\u001b[39m WriteBuffer[\u001b[39mbytes\u001b[39m] \u001b[39m=\u001b[39m io\u001b[39m.\u001b[39mBytesIO() \u001b[39mif\u001b[39;00m path \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m path\n\u001b[0;32m--> 483\u001b[0m impl\u001b[39m.\u001b[39;49mwrite(\n\u001b[1;32m    484\u001b[0m     df,\n\u001b[1;32m    485\u001b[0m     path_or_buf,\n\u001b[1;32m    486\u001b[0m     compression\u001b[39m=\u001b[39;49mcompression,\n\u001b[1;32m    487\u001b[0m     index\u001b[39m=\u001b[39;49mindex,\n\u001b[1;32m    488\u001b[0m     partition_cols\u001b[39m=\u001b[39;49mpartition_cols,\n\u001b[1;32m    489\u001b[0m     storage_options\u001b[39m=\u001b[39;49mstorage_options,\n\u001b[1;32m    490\u001b[0m     filesystem\u001b[39m=\u001b[39;49mfilesystem,\n\u001b[1;32m    491\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m    492\u001b[0m )\n\u001b[1;32m    494\u001b[0m \u001b[39mif\u001b[39;00m path \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    495\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(path_or_buf, io\u001b[39m.\u001b[39mBytesIO)\n",
      "File \u001b[0;32m~/miniconda3/envs/pb/lib/python3.10/site-packages/pandas/io/parquet.py:197\u001b[0m, in \u001b[0;36mPyArrowImpl.write\u001b[0;34m(self, df, path, compression, index, storage_options, partition_cols, filesystem, **kwargs)\u001b[0m\n\u001b[1;32m    194\u001b[0m     merged_metadata \u001b[39m=\u001b[39m {\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mexisting_metadata, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mdf_metadata}\n\u001b[1;32m    195\u001b[0m     table \u001b[39m=\u001b[39m table\u001b[39m.\u001b[39mreplace_schema_metadata(merged_metadata)\n\u001b[0;32m--> 197\u001b[0m path_or_handle, handles, filesystem \u001b[39m=\u001b[39m _get_path_or_handle(\n\u001b[1;32m    198\u001b[0m     path,\n\u001b[1;32m    199\u001b[0m     filesystem,\n\u001b[1;32m    200\u001b[0m     storage_options\u001b[39m=\u001b[39;49mstorage_options,\n\u001b[1;32m    201\u001b[0m     mode\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mwb\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    202\u001b[0m     is_dir\u001b[39m=\u001b[39;49mpartition_cols \u001b[39mis\u001b[39;49;00m \u001b[39mnot\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    203\u001b[0m )\n\u001b[1;32m    204\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m    205\u001b[0m     \u001b[39misinstance\u001b[39m(path_or_handle, io\u001b[39m.\u001b[39mBufferedWriter)\n\u001b[1;32m    206\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mhasattr\u001b[39m(path_or_handle, \u001b[39m\"\u001b[39m\u001b[39mname\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    207\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(path_or_handle\u001b[39m.\u001b[39mname, (\u001b[39mstr\u001b[39m, \u001b[39mbytes\u001b[39m))\n\u001b[1;32m    208\u001b[0m ):\n\u001b[1;32m    209\u001b[0m     path_or_handle \u001b[39m=\u001b[39m path_or_handle\u001b[39m.\u001b[39mname\n",
      "File \u001b[0;32m~/miniconda3/envs/pb/lib/python3.10/site-packages/pandas/io/parquet.py:139\u001b[0m, in \u001b[0;36m_get_path_or_handle\u001b[0;34m(path, fs, storage_options, mode, is_dir)\u001b[0m\n\u001b[1;32m    129\u001b[0m handles \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    130\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m    131\u001b[0m     \u001b[39mnot\u001b[39;00m fs\n\u001b[1;32m    132\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m is_dir\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[39m# fsspec resources can also point to directories\u001b[39;00m\n\u001b[1;32m    138\u001b[0m     \u001b[39m# this branch is used for example when reading from non-fsspec URLs\u001b[39;00m\n\u001b[0;32m--> 139\u001b[0m     handles \u001b[39m=\u001b[39m get_handle(\n\u001b[1;32m    140\u001b[0m         path_or_handle, mode, is_text\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, storage_options\u001b[39m=\u001b[39;49mstorage_options\n\u001b[1;32m    141\u001b[0m     )\n\u001b[1;32m    142\u001b[0m     fs \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    143\u001b[0m     path_or_handle \u001b[39m=\u001b[39m handles\u001b[39m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/miniconda3/envs/pb/lib/python3.10/site-packages/pandas/io/common.py:872\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    863\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(\n\u001b[1;32m    864\u001b[0m             handle,\n\u001b[1;32m    865\u001b[0m             ioargs\u001b[39m.\u001b[39mmode,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    868\u001b[0m             newline\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    869\u001b[0m         )\n\u001b[1;32m    870\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    871\u001b[0m         \u001b[39m# Binary mode\u001b[39;00m\n\u001b[0;32m--> 872\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(handle, ioargs\u001b[39m.\u001b[39;49mmode)\n\u001b[1;32m    873\u001b[0m     handles\u001b[39m.\u001b[39mappend(handle)\n\u001b[1;32m    875\u001b[0m \u001b[39m# Convert BytesIO or file objects passed with an encoding\u001b[39;00m\n",
      "\u001b[0;31mPermissionError\u001b[0m: [Errno 13] Permission denied: '/media/nvme1/pbecg-data/signal.parquet'"
     ]
    }
   ],
   "source": [
    "# Convert the acquisition time to a datetime object\n",
    "df[\"acq_time\"] = pd.to_datetime(df[\"acq_time\"], format=\"%Y%m%d%H%M%S\")\n",
    "# Store the dataset as a parquet file\n",
    "save_path = Path(\"/media/nvme1/pbecg-data/signal.parquet\")\n",
    "df.to_parquet(save_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ldapusers dremt pse-dunn-login\n"
     ]
    }
   ],
   "source": [
    "!groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
